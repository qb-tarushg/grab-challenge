{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from matplotlib import pyplot as plt\n",
    "from os.path import abspath, exists, join, dirname\n",
    "from scipy import io as sio\n",
    "\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path Parameters for the training, test dataset\n",
    "\n",
    "* DATA_HOME - Base directory for all data\n",
    "* TRAIN_DIR - Path for training dataset\n",
    "* TRAIN_LABEL_PATH - Path for training annotations/labels as mentioned in Stanford car dataset.\n",
    "* TEST_DIR, TEST_LABEL_PATH - Similarly for test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_HOME=abspath(\"./../data/\")\n",
    "TRAIN_DIR=join(DATA_HOME, \"cars_train/\")\n",
    "TEST_DIR=join(DATA_HOME, \"cars_test/\")\n",
    "TRAIN_LABEL_PATH=join(DATA_HOME, \"devkit/cars_train_annos.mat\")\n",
    "TEST_LABEL_PATH=join(DATA_HOME, \"devkit/cars_test_annos_withlabels.mat\")\n",
    "CLASSES_PATH=join(DATA_HOME, \"devkit/cars_meta.mat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the code repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('./../grab-challenge/src/python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import StanfordCarDataset, split, CarDataset\n",
    "from preprocess import FilterNonRGBCarImages\n",
    "from nnet import CarNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Names dictionary with its label ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_car_classes(path) -> np.ndarray:\n",
    "    carsMat = sio.loadmat(path)\n",
    "    _, nclasses = carsMat[\"class_names\"].shape\n",
    "    cars_classes = np.array(\n",
    "        [\n",
    "            (i + 1, carsMat[\"class_names\"][:, i][0][0])\n",
    "            for i in range(nclasses)\n",
    "        ]\n",
    "    )\n",
    "    return cars_classes\n",
    "\n",
    "class_names = get_car_classes(CLASSES_PATH)\n",
    "class_df = pd.DataFrame(class_names, columns=['class', 'class_name']).drop(columns=['class'])\\\n",
    "                                                        .reset_index().rename(columns={\"index\": \"class\"})\n",
    "CLASS_NAMES_DICT = class_df.to_dict()['class_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 196\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for training and evaluating the network for car's make and model\n",
    "\n",
    "The network is build upon transfer learning technique, it uses Resnet18 which is further modified to classify NUM_CLASSES = 196 for current case. We have added the resize step so as make compatible with resnet18 input image size.\n",
    "\n",
    "All steps are detailed below:\n",
    "\n",
    "## Steps :\n",
    "\n",
    "1. Data augmentation techniques - resize (224, 224), random horizontal flip and finally normalisation.\n",
    "\n",
    "2. All labels are decreased by value 1 so as to make an adjustment with model classification output. Model will give\n",
    "class ids starting with index 0 but in the dataset the labels start with 1.\n",
    "\n",
    "3. Preprocessing step as to filter out images which does not have dimension (x, y, 3). The step is applied for both train and test dataset.\n",
    "\n",
    "4. Load the dataset using DataLoader API of Pytorch along with custom dataset API `StanfordCarDataset`. The code for `StanfordCarDataset` API can be seen in module `dataset.py` in my repository.\n",
    "\n",
    "5. (Imp) Initialise the `checkpoint` directory (kindly make a directory if it does not exists).\n",
    "6. Initialise the `CarNet` neural network and run `fit` method using train_dataloader and val_dataloader.\n",
    "7. Method `evaluate` and `predict` are used for testing the model on unseen dataset `test_loader`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation techniques using Pytorch transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "target_transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda x: x - 1)\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\\\n",
    "    transforms.ToTensor(),\\\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_images = FilterNonRGBCarImages(TRAIN_DIR, TRAIN_LABEL_PATH).apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = StanfordCarDataset(TRAIN_DIR, filtered_images.rgb, transform=train_transform,\\\n",
    "                                   label_transform=target_transform)\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_test_filtered_images = FilterNonRGBCarImages(TEST_DIR, TEST_LABEL_PATH).apply()\n",
    "val_test_dataset = StanfordCarDataset(TEST_DIR, val_test_filtered_images.rgb, transform=val_test_transform,\\\n",
    "                                     label_transform=target_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset, test_dataset = split(val_test_dataset, split_ratio=0.6)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_folder = abspath(\"./../checkpoint\")\n",
    "\n",
    "car_net = CarNet(NUM_CLASSES, require_chkpoint=True, chkpnt_folder=checkpoint_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running epoch 1/16\n",
      "---------------\n",
      "Completed in 11m 47s training loss: 4.0904, accuracy: 0.1301\n",
      "Completed in 2m 23s validation loss: 3.5577, accuracy: 0.1672\n",
      "Running epoch 2/16\n",
      "---------------\n",
      "Completed in 11m 46s training loss: 2.1554, accuracy: 0.4331\n",
      "Completed in 2m 23s validation loss: 2.5487, accuracy: 0.3342\n",
      "Running epoch 3/16\n",
      "---------------\n",
      "Completed in 11m 47s training loss: 1.2512, accuracy: 0.6526\n",
      "Completed in 2m 28s validation loss: 2.2451, accuracy: 0.4224\n",
      "Running epoch 4/16\n",
      "---------------\n",
      "Completed in 11m 45s training loss: 0.7768, accuracy: 0.7765\n",
      "Completed in 2m 24s validation loss: 1.7736, accuracy: 0.5261\n",
      "Running epoch 5/16\n",
      "---------------\n",
      "Completed in 11m 47s training loss: 0.4822, accuracy: 0.8645\n",
      "Completed in 2m 24s validation loss: 1.4367, accuracy: 0.6147\n",
      "Running epoch 6/16\n",
      "---------------\n",
      "Completed in 11m 46s training loss: 0.3028, accuracy: 0.9159\n",
      "Completed in 2m 24s validation loss: 1.4517, accuracy: 0.6118\n",
      "Running epoch 7/16\n",
      "---------------\n",
      "Completed in 11m 48s training loss: 0.1209, accuracy: 0.9735\n",
      "Completed in 2m 24s validation loss: 0.7736, accuracy: 0.7823\n",
      "Running epoch 8/16\n",
      "---------------\n",
      "Completed in 11m 45s training loss: 0.0616, accuracy: 0.9908\n",
      "Completed in 2m 20s validation loss: 0.7428, accuracy: 0.7902\n",
      "Running epoch 9/16\n",
      "---------------\n",
      "Completed in 11m 42s training loss: 0.0467, accuracy: 0.9951\n",
      "Completed in 2m 20s validation loss: 0.7290, accuracy: 0.7961\n",
      "Running epoch 10/16\n",
      "---------------\n",
      "Completed in 11m 43s training loss: 0.0390, accuracy: 0.9961\n",
      "Completed in 2m 20s validation loss: 0.7198, accuracy: 0.7956\n",
      "Running epoch 11/16\n",
      "---------------\n",
      "Completed in 11m 43s training loss: 0.0322, accuracy: 0.9967\n",
      "Completed in 2m 43s validation loss: 0.7088, accuracy: 0.8010\n",
      "Running epoch 12/16\n",
      "---------------\n",
      "Completed in 13m 6s training loss: 0.0273, accuracy: 0.9967\n",
      "Completed in 2m 20s validation loss: 0.7120, accuracy: 0.8012\n",
      "Running epoch 13/16\n",
      "---------------\n",
      "Completed in 11m 55s training loss: 0.0245, accuracy: 0.9980\n"
     ]
    }
   ],
   "source": [
    "car_net.fit(train_dataloader, val_loader, epochs=16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
